{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = open('/home/lindb/pythonimports.py').read()\n",
    "exec(imp)\n",
    "from datetime import datetime as dt\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test out datatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in fs('/scratch/lindb/testdata') if f.endswith('fastq.gz')]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = pickle.load(open('/scratch/lindb/testdata/rginfo.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.read_csv('/scratch/lindb/testdata/1_CoAdapTree_Seq_Summary.txt',sep='\\t')\n",
    "summary.columns = [x.lower() for x in summary.columns]\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in summary.index:\n",
    "    samp = summary.loc[row,'sample_name']\n",
    "    f = sorted([f for f in files if samp in f])\n",
    "    assert len(f) == 2\n",
    "    summary.loc[row,'file_name_r1'] = op.basename(f[0])\n",
    "    summary.loc[row,'file_name_r2'] = op.basename(f[1])\n",
    "    for key in ['rgid','rglb','rgpl','rgpu','rgsm']:\n",
    "        summary.loc[row,key] = rg[samp][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summary[['sample_name','pool_name','ploidy','file_name_r1','file_name_r2','index1','index2','adaptor_1',\n",
    "                   'adaptor_2','rgid','rglb','rgpl','rgpu','rgsm']]\n",
    "filE = op.join('/scratch/lindb/testdata/datatable.txt')\n",
    "summary.to_csv(filE,header=True,sep='\\t',index=None)\n",
    "s = pd.read_csv(filE,sep='\\t')\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/scratch/lindb/testdata/datatable.txt',sep='\\t')\n",
    "rginfo = {}\n",
    "f2pool = {}\n",
    "for row in data.index:\n",
    "    if type(data.loc[row,'pool_name']) == float: # if pool_name is blank/nan\n",
    "        data.loc[row,'pool_name'] = data.loc[row,'sample_name']\n",
    "    samp = data.loc[row,'sample_name']\n",
    "    rginfo[samp] = {}\n",
    "    for col in data.columns[-5:]:\n",
    "        rginfo[samp][col] = data.loc[row,col]    \n",
    "    for f in [data.loc[row,'file_name_r1'],data.loc[row,'file_name_r2']]:\n",
    "        f2pool[f] = data.loc[row,'pool_name']\n",
    "f2pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('/scratch/lindb/testdata/datatable.txt',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = pd.read_csv('/scratch/lindb/testdata/datatable.txt',sep='\\t')\n",
    "d2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = 'LP_mg_cap2_kit1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2[d2['pool_name'] == pool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pool in uni(d2['pool_name']):\n",
    "    df = d2[d2['pool_name'] == pool]\n",
    "    print pool, luni(df['ploidy']),uni(df['ploidy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ploidy = {}\n",
    "for row in d2.index:\n",
    "    if type(d2.loc[row,'pool_name']) == float: # if pool_name is blank/nan, it is a poolseq\n",
    "        d2.loc[row,'pool_name'] = d2.loc[row,'sample_name']\n",
    "    samp = d2.loc[row,'sample_name']\n",
    "    pool = d2.loc[row,'pool_name']\n",
    "    df = d2[d2['pool_name'] == pool].copy()\n",
    "    try:\n",
    "        assert luni(df['ploidy']) == 1\n",
    "    except AssertionError as e:\n",
    "        print \"the ploidy values for some elements with pool name '%s' are not the same\" % pool\n",
    "        sys.exit(1)\n",
    "    if not pool in ploidy:\n",
    "        ploidy[pool] = d2.loc[row,'ploidy']\n",
    "ploidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fqdir = '/scratch/lindb/testdata/'\n",
    "pkldump(ploidy,op.join(fqdir,'ploidy.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ploidy = pickle.load(open(op.join(fqdir,'ploidy.pkl')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pools = uni(d2['pool_name'].tolist())\n",
    "pooldirs = []\n",
    "for p in pools:\n",
    "    DIR = op.join(fqdir,p)\n",
    "    if not op.exists(DIR):\n",
    "        os.makedirs(DIR)\n",
    "    if op.exists(DIR):\n",
    "        pooldirs.append(DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pooldirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = op.join(fqdir,'ploidy.pkl')\n",
    "assert op.exists(src)\n",
    "for p in pooldirs:\n",
    "    dst = op.join(p,'ploidy.pkl')\n",
    "    if not op.exists(dst):\n",
    "        os.symlink(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in fs(fqdir) if 'fastq' in f and 'md5' not in f]\n",
    "datafiles = data['file_name_r1'].tolist()\n",
    "[datafiles.append(x) for x in data['file_name_r2'].tolist()]\n",
    "for f in datafiles:\n",
    "    try:\n",
    "        src = op.join(fqdir,f)\n",
    "        assert op.exists(src)\n",
    "        pooldir = op.join(fqdir,f2pool[f])\n",
    "        dst = op.join(pooldir,f)\n",
    "        os.symlink(src,dst)\n",
    "    except AssertionError as e:\n",
    "        print 'could not find %s in %s' % (f,fqdir)\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooldirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/scratch/lindb/testdata/datatable.txt',sep='\\t')\n",
    "for row in data.index:\n",
    "    spp = data.loc[row,'sample_name'].split(\"_\")[0]\n",
    "    if spp in ['LP','JP']:\n",
    "        data.loc[row,'ref'] = \"/scratch/lindb/refgenomes/LP_db/ptaeda.v1.01.reduced.pseudo.fasta\"\n",
    "        #print spp\n",
    "    else:\n",
    "        data.loc[row,'ref'] = 'TBD'\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'ref' in data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['sample_name','pool_name','ploidy','file_name_r1','file_name_r2','index1','index2','adaptor_1',\n",
    "                   'adaptor_2','ref','rgid','rglb','rgpl','rgpu','rgsm']]\n",
    "data.to_csv('/scratch/lindb/testdata/datatable.txt',header=True,index=None,sep='\\t')\n",
    "d = pd.read_csv('/scratch/lindb/testdata/datatable.txt',sep='\\t')\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shdir = '/scratch/lindb/testdata/shfiles/'\n",
    "for s in fs(shdir):\n",
    "    os.chdir(shdir)\n",
    "    bname = op.basename(s)\n",
    "    if bname.startswith('JP') or bname.startswith('LP'):\n",
    "        print s\n",
    "        !sbatch $s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata = pd.read_csv('/scratch/lindb/practice/datatable.txt',sep='\\t')\n",
    "pdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata = pdata[pdata['file_name_r1'] == 'HI.4779.005.D701---D504.LP_mg8_cap2_kit1_R1.fastq.gz'].copy()\n",
    "pdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filE = '/scratch/lindb/practice/datatable.txt'\n",
    "pdata.to_csv(filE,index=None,sep='\\t')\n",
    "p = pd.read_csv(filE,sep='\\t')\n",
    "p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.columns[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figure out fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = '/scratch/lindb/testdata/'\n",
    "files = [f for f in fs(DIR) if '.out' in f]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    print f\n",
    "    print open(f,'r').read()\n",
    "    print '#############################################################################'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get filter stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fqdir = '/scratch/lindb/testdata/JP_cap3_kit1/'\n",
    "shdir = op.join(fqdir,'shfiles')\n",
    "trimdir = op.join(shdir,'trimmed_shfiles')\n",
    "files = [f for f in fs(trimdir) if '.out' in f]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fqual = {}\n",
    "for f in files:\n",
    "    fqual[f] = {}\n",
    "    r = open(f,'r').readlines()\n",
    "#    print r\n",
    "    print '###############################################################################'\n",
    "    fqual[f]['r1b4']    = r[1].split(\" \")[-1].replace(\"\\n\",\"\")\n",
    "    fqual[f]['r1q20']   = r[3].split(\"(\")[-1].replace(\"%)\\n\",\"\")\n",
    "    fqual[f]['r1q30']   = r[4].split(\"(\")[-1].replace(\"%)\\n\",\"\")\n",
    "    fqual[f]['r1after']      = r[7].split(\" \")[-1].replace(\"\\n\",\"\")\n",
    "    fqual[f]['r1q20after']   = r[9].split(\"(\")[-1].replace(\"%)\\n\",\"\")\n",
    "    fqual[f]['r1q30after']   = r[10].split(\"(\")[-1].replace(\"%)\\n\",\"\")\n",
    "    \n",
    "    fqual[f]['r2b4']    = r[13].split(\" \")[-1].replace(\"\\n\",\"\")\n",
    "    fqual[f]['r2q20']   = r[15].split(\"(\")[-1].replace(\"%)\\n\",\"\")\n",
    "    fqual[f]['r2q30']   = r[16].split(\"(\")[-1].replace(\"%)\\n\",\"\")\n",
    "    fqual[f]['r2after']    = r[19].split(\" \")[-1].replace(\"\\n\",\"\")\n",
    "    fqual[f]['r2q20after'] = r[21].split(\"(\")[-1].replace(\"%)\\n\",\"\")\n",
    "    fqual[f]['r2q30after'] = r[22].split(\"(\")[-1].replace(\"%)\\n\",\"\")\n",
    "    \n",
    "    for key in fqual[f]:\n",
    "        fqual[f][key] = float(fqual[f][key])\n",
    "    \n",
    "    fqual[f]['diffbeforeafter'] = fqual[f]['r1b4'] - fqual[f]['r1after']\n",
    "    \n",
    "    fqual[f]['time'] = r[-2].split(\" \")[-2].replace(\"\\n\",\"\")\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fqual[f]['diffbeforeafter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10045959 - 2770320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7275639*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in r:\n",
    "    print line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run fastqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fqdir = '/scratch/lindb/testdata/'\n",
    "os.chdir(fqdir)\n",
    "dirs = !ls -d */\n",
    "dirs = [op.join(op.abspath(d),'trimmed') for d in dirs if 'kit' in d and 'LP' in d or 'JP' in d]\n",
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastqs = [f for d in dirs for f in fs(d) if f.endswith('fastq')]\n",
    "len(fastqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shfiles = []\n",
    "shdirs = []\n",
    "for fastq in fastqs:\n",
    "    bname = op.basename(fastq)\n",
    "    d     = op.dirname(fastq)\n",
    "    fqdir = op.dirname(d)\n",
    "    text  = '''#!/bin/bash\n",
    "#SBATCH --account=def-saitken\n",
    "#SBATCH --job-name=fastqc%s\n",
    "#SBATCH --export=all\n",
    "#SBATCH --time=02:59:00\n",
    "#SBATCH --mem=500mb\n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --output=fastqc%s_%%j.out\n",
    "\n",
    "module load fastqc\n",
    "fastqc -o %s --noextract %s\n",
    "''' % (bname,\n",
    "       bname,\n",
    "       d,\n",
    "       fastq)\n",
    "    shdir = op.join(fqdir,'shfiles/fastqc')\n",
    "    shdirs.append(shdir)\n",
    "#     os.chdir(shdir)\n",
    "#     !rm *\n",
    "    if not op.exists(shdir):\n",
    "        os.makedirs(shdir)\n",
    "    filE = op.join(shdir,'fastqc_%s.sh' % bname)\n",
    "    with open(filE,'w') as o:\n",
    "        o.write(\"%s\" % text)\n",
    "    shfiles.append(filE)\n",
    "shfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in shfiles:\n",
    "    os.chdir(op.dirname(s))\n",
    "    !sbatch $s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# copy to mengmeng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fqdir = '/scratch/lindb/testdata/'\n",
    "os.chdir(fqdir)\n",
    "dirs = !ls -d */\n",
    "dirs = [op.join(op.abspath(d),'trimmed') for d in dirs if 'kit' in d and 'LP' in d or 'JP' in d]\n",
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for d in dirs:\n",
    "    [files.append(f) for f in fs(d) if 'html' in f]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op.exists(\"/scratch/mlu4uc/Tree_share/brandon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    newf = f.replace(\"/scratch/lindb\",\"/scratch/mlu4uc/Tree_share/brandon\")\n",
    "    if not op.exists(op.dirname(newf)):\n",
    "        os.makedirs(op.dirname(newf))\n",
    "    cp(f,newf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# determine how much memory and time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = '/home/lindb/scratch/testdata/'\n",
    "os.chdir(DIR)\n",
    "dirs = !ls -d */\n",
    "dirs = [d for d in dirs if 'LP' in d or 'JP' in d]\n",
    "slurms = []\n",
    "for d in dirs:\n",
    "    d = op.abspath(d)\n",
    "    t = op.join(d,'shfiles/trimmed_shfiles')\n",
    "    assert op.exists(t)\n",
    "    [slurms.append(f) for f in fs(t) if '.out' in f]\n",
    "slurms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in slurms:\n",
    "    s = op.basename(s)\n",
    "    pids.append(int(s.split(\"_\")[1].split(\".out\")[0]))\n",
    "len(pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mems  = []\n",
    "times = []\n",
    "for p in pids:\n",
    "    info = !seff $p\n",
    "    mem  = math.ceil(float([x for x in info if 'Memory Utilized' in x][0].split(\" \")[2]))\n",
    "    hours,minutes,seconds = [x for x in info if 'Job Wall-clock time' in x][0].split(\" \")[-1].split(\":\")\n",
    "    time = (int(hours)*60)+int(minutes)+(int(seconds)/60)\n",
    "    times.append(time)\n",
    "    mems.append(mem)\n",
    "np.mean(mems),np.mean(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bwa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwaslurms = []\n",
    "for d in dirs:\n",
    "    d = op.abspath(d)\n",
    "    t = op.join(d,'shfiles/bwa_shfiles')\n",
    "    assert op.exists(t)\n",
    "    [bwaslurms.append(f) for f in fs(t) if '.out' in f]\n",
    "bwaslurms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwapids = []\n",
    "for s in bwaslurms:\n",
    "    s = op.basename(s)\n",
    "    pid = int(s.split(\"_\")[1].split(\".out\")[0])\n",
    "    if pid in largemem:\n",
    "        print op.abspath(s)\n",
    "    bwapids.append(pid)\n",
    "len(bwapids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwamems  = []\n",
    "bwatimes = []\n",
    "count    = 0\n",
    "for p in bwapids:\n",
    "    info = !seff $p\n",
    "    mem  = math.ceil(float([x for x in info if 'Memory Utilized' in x][0].split(\" \")[2]))\n",
    "    hours,minutes,seconds = [x for x in info if 'Job Wall-clock time' in x][0].split(\" \")[-1].split(\":\")\n",
    "    time = (int(hours)*60)+int(minutes)+(int(seconds)/60)\n",
    "    bwatimes.append(time)\n",
    "    bwamems.append(mem)\n",
    "    count += 1\n",
    "np.mean(bwamems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bwatimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bwamems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sbatch startfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = '/home/lindb/scratch/testdata/shfiles'\n",
    "shfiles = ls(DIR)\n",
    "for f in shfiles:\n",
    "    spp = f.split(\"_\")[0]\n",
    "    if spp in ['JP','LP']:\n",
    "        s = op.join(DIR,f)\n",
    "        print s\n",
    "        !sbatch $s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# see which libraries have dedup_rg_filtered_indexed_sorted_bamfiles/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = '/home/lindb/testdata/'\n",
    "os.chdir(DIR)\n",
    "dirs = !ls -d */\n",
    "dirs = [op.realpath(d) for d in dirs if 'cap' in d and 'LP' in d or 'JP' in d]\n",
    "#dirs = [op.realpath(d) for d in dirs if 'cap' in d and 'LP' in d]\n",
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bamfiles = []\n",
    "for d in dirs:\n",
    "    ddir = op.join(d,'rg_filtered_indexed_sorted_bamfiles')\n",
    "    print ddir\n",
    "    [bamfiles.append(f) for f in fs(ddir) if f.endswith('bam')]\n",
    "len(bamfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out where a poolfile is\n",
    "count = 0\n",
    "for b in bamfiles:\n",
    "    if 'p101' in b:\n",
    "        print count\n",
    "        break\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bamfiles[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "ref = '/scratch/lindb/refgenomes/LP_db/ptaeda.v1.01.reduced.pseudo.fasta'\n",
    "fdir = op.join(DIR,'shfiles/kick')\n",
    "files = []\n",
    "if not op.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "for rgout in bamfiles:\n",
    "    fqdir = op.dirname(op.dirname(rgout))\n",
    "    cmd = '''#!/bin/bash\n",
    "#SBATCH --time=02:59:00\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --mem=500M\n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --job-name=kick%s\n",
    "#SBATCH --export=all\n",
    "#SBATCH --output=kick%s_%%j.out \n",
    "\n",
    "source activate py27\n",
    "cd $HOME/pipeline\n",
    "python 02_mark_build_scatter.py %s %s %s %s\n",
    "''' % (str(count).zfill(2),\n",
    "       str(count).zfill(2),\n",
    "       rgout,\n",
    "       fqdir,\n",
    "       ref,\n",
    "       str(count).zfill(3)\n",
    "      )\n",
    "    filE = op.join(fdir,'kick%s.sh' % str(count).zfill(2))\n",
    "    files.append(filE)\n",
    "    with open(filE,'w') as o:\n",
    "        o.write(\"%s\" % cmd)\n",
    "    \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path as op\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdir = '/home/lindb/testdata/shfiles/kick'\n",
    "assert op.exists(fdir)\n",
    "os.chdir(fdir)\n",
    "for f in fs(fdir):\n",
    "    if f.endswith('sh'):\n",
    "        print f\n",
    "        os.system('sbatch %s' % f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make intervals list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for individual files\n",
    "DIR = '/home/lindb/testdata/intervals/'\n",
    "idir = op.join(DIR,'individual')\n",
    "if not op.exists(idir):\n",
    "    os.makedirs(idir)\n",
    "[os.remove(f) for f in fs(idir)]\n",
    "\n",
    "names = []\n",
    "interval = 2\n",
    "for i in range(1,1000,interval):\n",
    "    name ='scaff_%s-%s' % (str(i).zfill(3),str(i+(interval-1)).zfill(3))\n",
    "    names.append(name)\n",
    "namecount = 0\n",
    "for name in names:\n",
    "    namecount += 1\n",
    "    print name\n",
    "    filE = op.join(idir,\"%s.list\" % name)\n",
    "    first,second = name.split(\"_\")[1].split(\"-\")\n",
    "    with open(filE,'w') as o:\n",
    "        first  = int(first)\n",
    "        second = int(second)+1\n",
    "        for i in range(first,second,1):\n",
    "            text = 'Scaffold_%i\\n' % i\n",
    "            o.write(\"%s\" % text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for poolseq samps\n",
    "DIR = '/scratch/lindb/testdata/intervals/'\n",
    "pdir = op.join(DIR,'pooled')\n",
    "if not op.exists(pdir):\n",
    "    os.makedirs(pdir)\n",
    "[os.remove(f) for f in fs(pdir)]\n",
    "\n",
    "poolnames = []\n",
    "interval = 1\n",
    "for i in range(1,1000,interval):\n",
    "    name ='scaff_%s-%s' % (str(i).zfill(3),str(i+(interval-1)).zfill(3))\n",
    "    poolnames.append(name)\n",
    "print 'len(names)=',len(names)\n",
    "namecount = 0\n",
    "for name in poolnames:\n",
    "    namecount += 1\n",
    "    print name\n",
    "    filE = op.join(pdir,\"%s.list\" % name)\n",
    "    first,second = name.split(\"_\")[1].split(\"-\")\n",
    "    with open(filE,'w') as o:\n",
    "        first  = int(first)\n",
    "        second = int(second)+1\n",
    "        for i in range(first,second,1):\n",
    "            text = 'Scaffold_%i\\n' % i\n",
    "            o.write(\"%s\" % text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifiles = ls(idir)\n",
    "\"scaff%s\" % ifiles[0].split(\".txt\")[0].split(\"scaff_\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ploidy = pickle.load(open(op.join(fqdir,'ploidy.pkl')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ploidy['JP_cap3_kit1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# do mark and build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = '/home/lindb/testdata/'\n",
    "os.chdir(DIR)\n",
    "dirs = !ls -d */\n",
    "dirs = [op.realpath(d) for d in dirs if 'cap' in d and 'LP' in d or 'JP' in d]\n",
    "#dirs = [op.realpath(d) for d in dirs if 'cap' in d and 'LP' in d]\n",
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bamfiles = []\n",
    "for d in dirs:\n",
    "    ddir = op.join(d,'rg_filtered_indexed_sorted_bamfiles')\n",
    "    print ddir\n",
    "    [bamfiles.append(f) for f in fs(ddir) if f.endswith('bam')]\n",
    "len(bamfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shdir = '/home/lindb/testdata/shfiles/markandbuild'\n",
    "ref = '/scratch/lindb/refgenomes/LP_db/ptaeda.v1.01.reduced.pseudo.fasta'\n",
    "if not op.exists(shdir):\n",
    "    os.makedirs(shdir)\n",
    "bamcount = 0\n",
    "for rgout in bamfiles:\n",
    "    fqdir   = op.dirname(op.dirname(rgout))\n",
    "    rgdir   = op.join(fqdir,'rg_filtered_indexed_sorted_bamfiles')\n",
    "    dupdir  = op.join(fqdir,'dedup_rg_filtered_indexed_sorted_bamfiles')\n",
    "    pool    = op.basename(op.dirname(op.dirname(rgout))) \n",
    "    samp    = op.basename(rgout).split(\"---\")[1].split(\"_R1R2\")[0].split(\".\")[1]\n",
    "#     print fqdir\n",
    "#     print rgout\n",
    "#     print samp\n",
    "#     print '\\n'\n",
    "    mout    = op.join(rgdir,\"%s.bam\" % samp)\n",
    "    dupfile = op.join(dupdir,\"%s_rd.bam\" % samp)\n",
    "    dupstat = op.join(dupdir,\"%s_rd_dupstat.txt\" % samp)\n",
    "    text = '''#!/bin/bash\n",
    "#SBATCH --time=02:59:00\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --mem=5000M\n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --job-name=markbuild%s\n",
    "#SBATCH --export=all\n",
    "#SBATCH --output=markbuild%s_%%j.out \n",
    "#SBATCH --mail-user=lindb@vcu.edu\n",
    "#SBATCH --mail-type=FAIL\n",
    "\n",
    "source $HOME/.bashrc\n",
    "\n",
    "# remove dups\n",
    "picard MarkDuplicates I=%s O=%s M=%s VALIDATION_STRINGENCY=LENIENT REMOVE_DUPLICATES=true\n",
    "\n",
    "# Build bam index for GATK\n",
    "picard BuildBamIndex I=%s\n",
    "\n",
    "cd $HOME/pipeline\n",
    "python 02_scatter-gvcf.py %s %s %s %s\n",
    "\n",
    "''' % (str(bamcount).zfill(2),\n",
    "       str(bamcount).zfill(2),\n",
    "       rgout, dupfile, dupstat,\n",
    "       dupfile,\n",
    "       rgout, fqdir, ref, bamcount\n",
    "      )\n",
    "    filE = op.join(shdir,'markbuild_%s.sh' % samp)\n",
    "    with open(filE,'w') as o:\n",
    "        o.write(\"%s\" % text)\n",
    "    bamcount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a catfile\n",
    "shdir = '/home/lindb/testdata/shfiles/markandbuild'\n",
    "catmark = op.join(shdir,'catmark.txt')\n",
    "catbuild = op.join(shdir,'catbuild.txt')\n",
    "if not op.exists(shdir):\n",
    "    os.makedirs(shdir)\n",
    "bamcount = 0\n",
    "for rgout in bamfiles:\n",
    "    fqdir   = op.dirname(op.dirname(rgout))\n",
    "    rgdir   = op.join(fqdir,'rg_filtered_indexed_sorted_bamfiles')\n",
    "    dupdir  = op.join(fqdir,'dedup_rg_filtered_indexed_sorted_bamfiles')\n",
    "    pool    = op.basename(op.dirname(op.dirname(rgout))) \n",
    "    samp    = op.basename(rgout).split(\"---\")[1].split(\"_R1R2\")[0].split(\".\")[1]\n",
    "#     print fqdir\n",
    "#     print rgout\n",
    "#     print samp\n",
    "#     print '\\n'\n",
    "    mout    = op.join(rgdir,\"%s.bam\" % samp)\n",
    "    dupfile = op.join(dupdir,\"%s_rd.bam\" % samp)\n",
    "    dupstat = op.join(dupdir,\"%s_rd_dupstat.txt\" % samp)\n",
    "    text1 = '''picard MarkDuplicates I=%s O=%s M=%s VALIDATION_STRINGENCY=LENIENT REMOVE_DUPLICATES=true\n",
    "''' % (rgout, dupfile, dupstat)\n",
    "    text2 = '''picard BuildBamIndex I=%s\n",
    "''' % dupfile\n",
    "    with open(catmark,'a') as o:\n",
    "        o.write(\"%s\" % text1)\n",
    "    with open(catbuild,'a') as o:\n",
    "        o.write(\"%s\" % text2)\n",
    "    bamcount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in fs('/home/lindb/testdata/shfiles/markandbuild'):\n",
    "    if f.endswith('.sh'):\n",
    "        os.system('sbatch %s' % f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bamfiles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try out new 02_scatter-gvcf.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = '/home/lindb/testdata/'\n",
    "os.chdir(DIR)\n",
    "dirs = !ls -d */\n",
    "dirs = [op.realpath(d) for d in dirs if 'cap' in d and 'LP' in d or 'JP' in d]\n",
    "#dirs = [op.realpath(d) for d in dirs if 'cap' in d and 'LP' in d]\n",
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bamfiles = []\n",
    "for d in dirs:\n",
    "    ddir = op.join(d,'rg_filtered_indexed_sorted_bamfiles')\n",
    "    print ddir\n",
    "    [bamfiles.append(f) for f in fs(ddir) if f.endswith('bam')]\n",
    "len(bamfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = '/home/lindb/testdata/shfiles/test_gvcf'\n",
    "if not op.exists(DIR):\n",
    "    os.makedirs(DIR)\n",
    "ref = '/home/lindb/scratch/refgenomes/LP_db/ptaeda.v1.01.reduced.pseudo.fasta'\n",
    "shcount = 0\n",
    "shfiles = []\n",
    "for rgout in bamfiles:\n",
    "    d = op.dirname(op.dirname(bamfiles[0]))\n",
    "    shstr = str(shcount).zfill(2)\n",
    "    text = '''#!/bin/bash\n",
    "#SBATCH --time=02:59:00\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --mem=500M\n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --job-name=testgvcf%s\n",
    "#SBATCH --export=all\n",
    "#SBATCH --output=testgvcf%s_%%j.out \n",
    "#SBATCH --mail-user=lindb@vcu.edu\n",
    "#SBATCH --mail-type=FAIL\n",
    "\n",
    "source $HOME/.bashrc\n",
    "cd $HOME/pipeline\n",
    "\n",
    "python 02_scatter-gvcf.py %s %s %s %s\n",
    "''' % (shstr,\n",
    "       shstr,\n",
    "       rgout, d, ref, shstr\n",
    "      )\n",
    "    filE = op.join(DIR,'testgvcf_%s.sh' % shstr)\n",
    "    with open(filE,'w') as o:\n",
    "        o.write(\"%s\" % text)\n",
    "    shfiles.append(filE)\n",
    "    shcount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = '/home/lindb/testdata/shfiles/test_gvcf'\n",
    "for f in fs(DIR):\n",
    "    if '.sh' in f:\n",
    "        os.system('sbatch %s' % f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = '/home/lindb/testdata/shfiles/test_gvcf'\n",
    "catfile = op.join(DIR,'catfile.txt')\n",
    "if not op.exists(DIR):\n",
    "    os.makedirs(DIR)\n",
    "ref = '/home/lindb/scratch/refgenomes/LP_db/ptaeda.v1.01.reduced.pseudo.fasta'\n",
    "shcount = 0\n",
    "shfiles = []\n",
    "for rgout in bamfiles:\n",
    "    d = op.dirname(op.dirname(rgout))\n",
    "    print d\n",
    "    shstr = str(shcount).zfill(2)\n",
    "    text = '''python /home/lindb/pipeline/02_scatter-gvcf.py %s %s %s %s\n",
    "''' % (rgout, d, ref, shstr\n",
    "      )\n",
    "    with open(catfile,'a') as o:\n",
    "        o.write(\"%s\" % text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bamfiles = []\n",
    "for d in dirs:\n",
    "    ddir = op.join(d,'dedup_rg_filtered_indexed_sorted_bamfiles')\n",
    "    print ddir\n",
    "    print len(ls(ddir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# take a look at the queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd = !squeue | grep 'PD N'\n",
    "print len(pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = !squeue | grep 'R 2'\n",
    "print len(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!squeue | grep 'PD N' | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = !squeue | grep 'PD N'\n",
    "print len(q)\n",
    "count = 0\n",
    "for line in q:\n",
    "    if 'lindb' in line:\n",
    "        print count\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = !squeue | grep 'PD N'\n",
    "print len(q)\n",
    "count = 0\n",
    "for line in q:\n",
    "    if 'lindb' in line:\n",
    "        print count\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running = !squeue | grep ' sh   R 2'\n",
    "count = 0\n",
    "for r in running:\n",
    "    if '.sh' not in r:\n",
    "        if 'sh' in r:\n",
    "            count += 1\n",
    "            print r\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!squeue | grep 'PD N' | grep '(Priority)' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q = !squeue | grep 'PD N'\n",
    "lasts = []\n",
    "for line in q:\n",
    "    last = line.split()[-1]\n",
    "    if not last in lasts:\n",
    "        if '(' in last:\n",
    "            lasts.append(last)\n",
    "    if last == '(PartitionTimeLimit)':\n",
    "        print line\n",
    "print lasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(5) == int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = ['hey','sillly']\n",
    "dst = ['you','bastard']\n",
    "zip(src,dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,4,5]\n",
    "[x.extend([i,i+4,i+10]) for i in range(5)]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert 6==5\n",
    "except Exception as e:\n",
    "    logging.exception(e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
